{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4UhdNeG/2JTp0qXx27NK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choijonghong/transformer/blob/main/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8%2B%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GychHDGyog2Q",
        "outputId": "74439d88-4682-41d0-d040-4c5f51a4eed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "--2025-08-25 05:10:29--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14628807 (14M) [text/plain]\n",
            "Saving to: ‘ratings_train.txt’\n",
            "\n",
            "ratings_train.txt   100%[===================>]  13.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-08-25 05:10:30 (143 MB/s) - ‘ratings_train.txt’ saved [14628807/14628807]\n",
            "\n",
            "--2025-08-25 05:10:30--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893335 (4.7M) [application/octet-stream]\n",
            "Saving to: ‘ratings_test.txt’\n",
            "\n",
            "ratings_test.txt    100%[===================>]   4.67M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-08-25 05:10:30 (104 MB/s) - ‘ratings_test.txt’ saved [4893335/4893335]\n",
            "\n",
            "훈련 샘플 수: 150000\n",
            "테스트 샘플 수: 50000\n",
            "         id                                           document  label\n",
            "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
            "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
            "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
            "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
            "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
            "Vocab size: 23687\n",
            "샘플 인코딩: (tensor([2, 3, 4, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0]), 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 1246.8972\n",
            "Epoch 2, Loss 998.1554\n",
            "테스트 정확도: 0.7792667560053603\n",
            "긍정\n",
            "부정\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 0. 환경 준비\n",
        "# ==========================================\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import math, random, re\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ==========================================\n",
        "# 1. NSMC 데이터 다운로드\n",
        "# ==========================================\n",
        "!wget -nc https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
        "!wget -nc https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
        "\n",
        "train_df = pd.read_table(\"ratings_train.txt\")\n",
        "test_df  = pd.read_table(\"ratings_test.txt\")\n",
        "\n",
        "print(\"훈련 샘플 수:\", len(train_df))\n",
        "print(\"테스트 샘플 수:\", len(test_df))\n",
        "print(train_df.head())\n",
        "\n",
        "# ==========================================\n",
        "# 2. 토크나이저 & Vocab 구축\n",
        "# ==========================================\n",
        "def simple_tokenizer(text):\n",
        "    # 한글/영문/숫자만 남기고 띄어쓰기 기준 토큰화\n",
        "    return re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9a-zA-Z ]\", \"\", str(text)).split()\n",
        "\n",
        "counter = Counter()\n",
        "for doc in train_df['document'].dropna():\n",
        "    counter.update(simple_tokenizer(doc))\n",
        "\n",
        "# 최소 5번 이상 나온 단어만 vocab에 포함\n",
        "min_freq = 5\n",
        "vocab = {\"<pad>\":0, \"<unk>\":1}\n",
        "for word, freq in counter.items():\n",
        "    if freq >= min_freq and word not in vocab:\n",
        "        vocab[word] = len(vocab)\n",
        "\n",
        "print(\"Vocab size:\", len(vocab))\n",
        "\n",
        "def encode(line, max_len=50):\n",
        "    tokens = [vocab.get(tok, vocab[\"<unk>\"]) for tok in simple_tokenizer(line)]\n",
        "    if len(tokens) < max_len:\n",
        "        tokens += [vocab[\"<pad>\"]] * (max_len - len(tokens))\n",
        "    return torch.tensor(tokens[:max_len], dtype=torch.long)\n",
        "\n",
        "train_data = [(encode(row['document']), row['label']) for _, row in train_df.iterrows() if pd.notna(row['document'])]\n",
        "test_data  = [(encode(row['document']), row['label']) for _, row in test_df.iterrows() if pd.notna(row['document'])]\n",
        "\n",
        "print(\"샘플 인코딩:\", train_data[0])\n",
        "\n",
        "# ==========================================\n",
        "# 3. Positional Encoding\n",
        "# ==========================================\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# ==========================================\n",
        "# 4. Transformer 분류기 정의\n",
        "# ==========================================\n",
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=vocab[\"<pad>\"])\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, 256)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_enc(x)\n",
        "        x = x.transpose(0,1)\n",
        "        out = self.encoder(x)\n",
        "        out = out.mean(dim=0)\n",
        "        return self.fc(out)\n",
        "\n",
        "# ==========================================\n",
        "# 5. 학습 준비\n",
        "# ==========================================\n",
        "model = TransformerClassifier(len(vocab)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 2  # Colab에서는 1~2 epoch만 돌려도 확인 가능\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    random.shuffle(data)\n",
        "    for i in range(0, len(data), bsz):\n",
        "        batch = data[i:i+bsz]\n",
        "        X = torch.stack([x for x,y in batch]).to(device)\n",
        "        y = torch.tensor([y for x,y in batch], dtype=torch.long).to(device)\n",
        "        yield X, y\n",
        "\n",
        "# ==========================================\n",
        "# 6. 학습 루프\n",
        "# ==========================================\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X,y in batchify(train_data, BATCH_SIZE):\n",
        "        out = model(X)\n",
        "        loss = criterion(out, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss {total_loss:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 7. 평가\n",
        "# ==========================================\n",
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for X,y in batchify(test_data, BATCH_SIZE):\n",
        "        pred = model(X).argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "print(\"테스트 정확도:\", correct / len(test_data))\n",
        "\n",
        "# ==========================================\n",
        "# 8. 직접 문장 예측\n",
        "# ==========================================\n",
        "def predict_sentiment(sentence):\n",
        "    model.eval()\n",
        "    X = encode(sentence).unsqueeze(0).to(device)\n",
        "    pred = model(X).argmax(dim=1).item()\n",
        "    return \"긍정\" if pred==1 else \"부정\"\n",
        "\n",
        "print(predict_sentiment(\"이 영화 아주 재미있다.\"))\n",
        "print(predict_sentiment(\"이 영화 정말 최악이다.\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_sentiment(\"정말지겨운 영화...이런거 누가 만들었어.\"))\n",
        "print(predict_sentiment(\"스토리도 별로고 지루했다.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx3PgA1VpN-i",
        "outputId": "ade878d1-b7af-4bce-c267-a032a6e48d6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "부정\n",
            "부정\n"
          ]
        }
      ]
    }
  ]
}